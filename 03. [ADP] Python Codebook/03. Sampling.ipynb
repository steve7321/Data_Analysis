{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff0f11f-d418-4c86-895a-6ad1bf3d36d2",
   "metadata": {},
   "source": [
    "## **3장 표본추출, 데이터 분할, 교차검증**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe06097-3d1e-42ed-a326-6173c75958ae",
   "metadata": {},
   "source": [
    "### **3-1. 표본추출**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ebbf85-c224-4235-83f9-b3c218e2224b",
   "metadata": {},
   "source": [
    "#### 단순랜덤추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517af6b3-2dfc-492f-a973-cff9110c38ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length  sepal width  petal length  petal width  target\n",
      "0           5.1          3.5           1.4          0.2     0.0\n",
      "1           4.9          3.0           1.4          0.2     0.0\n",
      "2           4.7          3.2           1.3          0.2     0.0\n",
      "3           4.6          3.1           1.5          0.2     0.0\n",
      "4           5.0          3.6           1.4          0.2     0.0\n"
     ]
    }
   ],
   "source": [
    "# Scikit learn의 내장 데이터 iris 불러오기\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "data = load_iris()\n",
    "iris_cols = list(data['feature_names']) + ['target']\n",
    "iris = DataFrame(np.c_[data['data'], data['target']], columns = [col.replace(\" (cm)\", \"\") for col in iris_cols])\n",
    "print(iris.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fb3fc5-d8c4-4478-860c-c8c36a63ef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  target\n",
       "0             5.1          3.5           1.4          0.2     0.0\n",
       "100           6.3          3.3           6.0          2.5     2.0\n",
       "143           6.8          3.2           5.9          2.3     2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.sample(n=3, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f203385-ad9c-4188-89f0-8f94f8c4480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  target\n",
       "127           6.1          3.0           4.9          1.8     2.0\n",
       "94            5.6          2.7           4.2          1.3     1.0\n",
       "80            5.5          2.4           3.8          1.1     1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.sample(frac=0.3).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e0b2e59-91ba-4d63-a36a-734c6a9091d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal width</th>\n",
       "      <th>target</th>\n",
       "      <th>sepal width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal width  target  sepal width\n",
       "0          0.2     0.0          3.5\n",
       "1          0.2     0.0          3.0\n",
       "2          0.2     0.0          3.2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.sample(n=3, axis=1).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f757716b-24c6-4ba3-a2d8-68470adcb7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 'b']\n",
      "['5' '1' 'c' '3']\n",
      "[4 5 9]\n",
      "[[0.58358362 0.35019025]\n",
      " [0.09830251 0.31860122]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "data_list = [1,2,3,4,5,'a','b','c']\n",
    "print(random.sample(data_list,4))\n",
    "print(np.random.choice(data_list,4))\n",
    "\n",
    "print(np.random.randint(0,10,3))\n",
    "print(np.random.rand(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149e96f-951d-4b00-8428-525a5f1e572b",
   "metadata": {},
   "source": [
    "#### 계통추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13017362-bd85-4622-bf37-fbe012d69a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 150\n",
      "n: 8\n",
      "K: 18\n",
      "     sepal length  sepal width  petal length  petal width  target\n",
      "11            4.8          3.4           1.6          0.2     0.0\n",
      "29            4.7          3.2           1.6          0.2     0.0\n",
      "47            4.6          3.2           1.4          0.2     0.0\n",
      "65            6.7          3.1           4.4          1.4     1.0\n",
      "83            6.0          2.7           5.1          1.6     1.0\n",
      "101           5.8          2.7           5.1          1.9     2.0\n",
      "119           6.0          2.2           5.0          1.5     2.0\n",
      "137           6.4          3.1           5.5          1.8     2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data, n = iris, 8\n",
    "N = len(data)\n",
    "K = N//n  #구간 내 샘플 수\n",
    "index = data.loc[:K].sample(1).index  #첫 구간에서 임의로 선택한 샘플 인덱스\n",
    "sys_df = DataFrame()\n",
    "while len(sys_df) < n:\n",
    "    sys_df = pd.concat ([sys_df, data.loc[index,:]])\n",
    "    index += K\n",
    "\n",
    "print(f'N: {N}')\n",
    "print(f'n: {n}')\n",
    "print(f'K: {K}')\n",
    "print(sys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b1604-03f9-4bed-bdb2-05eb9844d046",
   "metadata": {},
   "source": [
    "#### 집락 추출법\n",
    "군집별로 랜덤추출법 수행 / 지역 & 다단계표본추출 / 층화추출법에서 층을 집락으로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9a35e-4bc5-4cfe-a5cd-b2bb4d304ac8",
   "metadata": {},
   "source": [
    "#### 층화추출법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d122882-4538-4f6b-a153-056540bab7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0.0    50\n",
      "1.0    50\n",
      "2.0    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# target을 층 혹은 집락이라고 가정!\n",
    "# 원본 데이터의 분포 확인\n",
    "from pandas import DataFrame, concat\n",
    "print(iris['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17dab53c-eddd-46bf-902e-edc7f62a419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "21            5.1          3.7           1.5          0.4     0.0\n",
      "8             4.4          2.9           1.4          0.2     0.0\n",
      "5             5.4          3.9           1.7          0.4     0.0\n",
      "76            6.8          2.8           4.8          1.4     1.0\n",
      "79            5.7          2.6           3.5          1.0     1.0\n",
      "62            6.0          2.2           4.0          1.0     1.0\n",
      "142           5.8          2.7           5.1          1.9     2.0\n",
      "134           6.1          2.6           5.6          1.4     2.0\n",
      "110           6.5          3.2           5.1          2.0     2.0\n"
     ]
    }
   ],
   "source": [
    "# 데이터, 층/집락 정보를 가진 컬럼명, 추출표본 개수\n",
    "data, stratum, sampling_no = iris, 'target', 9\n",
    "\n",
    "# 비례층화추출법: 원본 데이터의 비율대로 추출\n",
    "levels = data[stratum].unique()\n",
    "total = data[stratum].value_counts().sum()\n",
    "prop_val = data[stratum].value_counts()/total\n",
    "no = prop_val * sampling_no\n",
    "result = DataFrame()\n",
    "for level in levels:\n",
    "    temp_df = data[data[stratum]==level].sample(int(no[level]))\n",
    "    result = concat([result, temp_df])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42c369a7-eb07-477f-9345-78434467bc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  target\n",
      "33            5.5          4.2           1.4          0.2     0.0\n",
      "43            5.0          3.5           1.6          0.6     0.0\n",
      "64            5.6          2.9           3.6          1.3     1.0\n",
      "58            6.6          2.9           4.6          1.3     1.0\n",
      "92            5.8          2.6           4.0          1.2     1.0\n",
      "85            6.0          3.4           4.5          1.6     1.0\n",
      "53            5.5          2.3           4.0          1.3     1.0\n",
      "143           6.8          3.2           5.9          2.3     2.0\n",
      "102           7.1          3.0           5.9          2.1     2.0\n",
      "126           6.2          2.8           4.8          1.8     2.0\n"
     ]
    }
   ],
   "source": [
    "# 불비례층화추출법: 임의로 정한 특정 비율대로 샘플링\n",
    "# 데이터, 층/집락 정보를 가진 컬럼명, 추출표본 개수, 각 층/집락의 비율\n",
    "data, stratum, sampling_no, proportion = iris, 'target', 10, {0:0.2, 1:0.5, 2:0.3}\n",
    "\n",
    "levels = list(proportion.keys())\n",
    "prop_val = np.array(list(proportion.values()))\n",
    "no = prop_val * sampling_no\n",
    "result = DataFrame()\n",
    "for level in levels:\n",
    "    temp_df = data[data[stratum]==level].sample(int(no[level]))\n",
    "    result = concat([result, temp_df])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64122a9-849b-4760-9a11-eb4972ba6c2c",
   "metadata": {},
   "source": [
    "### **3-2. 데이터 분할**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba121510-87d3-470f-b361-be87909fef2a",
   "metadata": {},
   "source": [
    "#### 일반적 데이터 분할 및 홀드아웃 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f91376c8-0cec-4b95-b9d9-ab9cc73e4fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train(y_train): 105(105), X_test(y_test): 45(45)\n",
      "X_train의 비율: 0.70, X_test의 비율: 0.30 \n",
      "\n",
      "X_train(y_train): 75(75), X_test(y_test): 75(75)\n",
      "X_train의 비율: 0.50, X_test의 비율: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = iris.drop('target', axis=1)\n",
    "y = iris.filter(['target'])\n",
    "\n",
    "# 일반적 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"X_train(y_train): %d(%d), X_test(y_test): %d(%d)\"%(len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "print(\"X_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)), \"\\n\")\n",
    "\n",
    "# 홀드아웃방법\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "print(\"X_train(y_train): %d(%d), X_test(y_test): %d(%d)\"%(len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "print(\"X_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82861c-fa8d-407d-b78e-f1a12165fc90",
   "metadata": {},
   "source": [
    "#### Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f7bb0369-e626-43cf-8fe1-b0bb4b68b28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [ 71  42 107], test_index: [145  19  92]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({0.0: 28, 2.0: 27, 1.0: 20})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 30, 2.0: 23, 0.0: 22}) \n",
      "\n",
      "Sample 1 ==> train_index: [ 30 115 110], test_index: [ 85 100  61]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({0.0: 26, 2.0: 25, 1.0: 24})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 26, 2.0: 25, 0.0: 24}) \n",
      "\n",
      "Sample 2 ==> train_index: [147 130 104], test_index: [ 30 146  17]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({1.0: 28, 2.0: 24, 0.0: 23})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 27, 2.0: 26, 1.0: 22}) \n",
      "\n",
      "Sample 3 ==> train_index: [ 58  23 142], test_index: [  3  22 118]\n",
      "\tX_train의 비율: 0.50, X_test의 비율: 0.50\n",
      "\ty_train의 타겟 구성: Counter({1.0: 27, 2.0: 26, 0.0: 22})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 28, 2.0: 24, 1.0: 23}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from collections import Counter\n",
    "ss = ShuffleSplit(test_size=0.5, train_size=0.5, n_splits=4)\n",
    "for i, (train_index, test_index) in enumerate(ss.split(X)):\n",
    "    print(f\"Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}\")\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print(\"\\ty_train의 타겟 구성:\", Counter(y_train['target']))\n",
    "    print(\"\\ty_test의 타겟 구성:\", Counter(y_test['target']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c561e8-e298-4389-9179-3dd046c3592c",
   "metadata": {},
   "source": [
    "#### K-fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3649aaa-d3d4-4f63-a132-230ac0314ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [38 39 40], test_index: [0 1 2]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 50, 2.0: 50, 0.0: 12})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 38}) \n",
      "\n",
      "Sample 1 ==> train_index: [0 1 2], test_index: [38 39 40]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({2.0: 50, 0.0: 38, 1.0: 24})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 26, 0.0: 12}) \n",
      "\n",
      "Sample 2 ==> train_index: [0 1 2], test_index: [76 77 78]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 50, 2.0: 37, 1.0: 26})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 24, 2.0: 13}) \n",
      "\n",
      "Sample 3 ==> train_index: [0 1 2], test_index: [113 114 115]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 50, 1.0: 50, 2.0: 13})\n",
      "\ty_test의 타겟 구성: Counter({2.0: 37}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "#n_splits=fold 개수, shuffle=데이터 분할 전 shuffle 여부\n",
    "kf = KFold(n_splits=4, shuffle=False) \n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}\")\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print(\"\\ty_train의 타겟 구성:\", Counter(y_train['target']))\n",
    "    print(\"\\ty_test의 타겟 구성:\", Counter(y_test['target']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482d17ac-2e21-4e95-b1b2-22790a6752d6",
   "metadata": {},
   "source": [
    "#### Stratified K-fold 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df1f9e9d-e55c-4fa1-87fc-a3d75343a528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [13 14 15], test_index: [0 1 2]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 38, 0.0: 37, 2.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 13, 2.0: 13, 1.0: 12}) \n",
      "\n",
      "Sample 1 ==> train_index: [0 1 2], test_index: [13 14 15]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({1.0: 38, 0.0: 37, 2.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({0.0: 13, 2.0: 13, 1.0: 12}) \n",
      "\n",
      "Sample 2 ==> train_index: [0 1 2], test_index: [26 27 28]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 38, 2.0: 38, 1.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 13, 0.0: 12, 2.0: 12}) \n",
      "\n",
      "Sample 3 ==> train_index: [0 1 2], test_index: [38 39 40]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ty_train의 타겟 구성: Counter({0.0: 38, 2.0: 38, 1.0: 37})\n",
      "\ty_test의 타겟 구성: Counter({1.0: 13, 0.0: 12, 2.0: 12}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "# 분할 시 y를 고려해야 하기 때문에 split에 y를 입력!\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}\")\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print(\"\\ty_train의 타겟 구성:\", Counter(y_train['target']))\n",
    "    print(\"\\ty_test의 타겟 구성:\", Counter(y_test['target']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6e0b6-517c-4ee7-afe6-4e59f2d27628",
   "metadata": {},
   "source": [
    "#### Group K-fold 분할\n",
    "범주형 범수인 Group을 각 분할마다 검증용 데이터로 사용하는 K-fold 진행방식 (ex. G1 그룹 데이터들을 1번째 샘플의 Test set으로 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb0b3f85-52be-4694-9e83-e75901a6e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'g1': 42, 'g3': 37, 'g0': 36, 'g2': 35})\n",
      "   sepal length  sepal width  petal length  petal width  target group\n",
      "0           5.1          3.5           1.4          0.2     0.0    g1\n",
      "1           4.9          3.0           1.4          0.2     0.0    g2\n",
      "2           4.7          3.2           1.3          0.2     0.0    g2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunwa\\AppData\\Local\\Temp\\ipykernel_16420\\862415442.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  iris2['group'] = iris2['target'].apply(lambda x: f\"g{int(np.random.randint(0,4,1))}\")\n"
     ]
    }
   ],
   "source": [
    "# group 변수가 있는 데이터를 생성\n",
    "## group의 수준은 g0, g1, g2, g3의 4종류가 있다.\n",
    "iris2 = iris.copy()\n",
    "iris2['group'] = iris2['target'].apply(lambda x: f\"g{int(np.random.randint(0,4,1))}\")\n",
    "print(Counter(iris2['group']))\n",
    "print(iris2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9e72ffa-3bbd-4759-a5f1-8348276e8087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 ==> train_index: [1 2 3], test_index: [0 5 6]\n",
      "\tX_train의 비율: 0.72, X_test의 비율: 0.28\n",
      "\ttrain의 타겟 구성: Counter({0.0: 40, 1.0: 34, 2.0: 34})\n",
      "\ttest의 타겟 구성: Counter({1.0: 16, 2.0: 16, 0.0: 10})\n",
      "\ttrain의 그룹 구성: Counter({'g3': 37, 'g0': 36, 'g2': 35})\n",
      "\ttest의 그룹 구성: Counter({'g1': 42}) \n",
      "\n",
      "Sample 1 ==> train_index: [0 1 2], test_index: [ 8 12 15]\n",
      "\tX_train의 비율: 0.75, X_test의 비율: 0.25\n",
      "\ttrain의 타겟 구성: Counter({2.0: 40, 0.0: 38, 1.0: 35})\n",
      "\ttest의 타겟 구성: Counter({1.0: 15, 0.0: 12, 2.0: 10})\n",
      "\ttrain의 그룹 구성: Counter({'g1': 42, 'g0': 36, 'g2': 35})\n",
      "\ttest의 그룹 구성: Counter({'g3': 37}) \n",
      "\n",
      "Sample 2 ==> train_index: [0 1 2], test_index: [ 4  7 11]\n",
      "\tX_train의 비율: 0.76, X_test의 비율: 0.24\n",
      "\ttrain의 타겟 구성: Counter({2.0: 39, 1.0: 38, 0.0: 37})\n",
      "\ttest의 타겟 구성: Counter({0.0: 13, 1.0: 12, 2.0: 11})\n",
      "\ttrain의 그룹 구성: Counter({'g1': 42, 'g3': 37, 'g2': 35})\n",
      "\ttest의 그룹 구성: Counter({'g0': 36}) \n",
      "\n",
      "Sample 3 ==> train_index: [0 4 5], test_index: [1 2 3]\n",
      "\tX_train의 비율: 0.77, X_test의 비율: 0.23\n",
      "\ttrain의 타겟 구성: Counter({1.0: 43, 2.0: 37, 0.0: 35})\n",
      "\ttest의 타겟 구성: Counter({0.0: 15, 2.0: 13, 1.0: 7})\n",
      "\ttrain의 그룹 구성: Counter({'g1': 42, 'g3': 37, 'g0': 36})\n",
      "\ttest의 그룹 구성: Counter({'g2': 35}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "X = iris2.drop(['target', 'group'], axis=1)\n",
    "y = iris2.filter(['target'])\n",
    "group = iris2.filter(['group'])\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "# 분할 시 group을 고려해야 하기 때문에 split에 group를 입력!\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(X, y, group)):\n",
    "    print(f\"Sample {i} ==> train_index: {train_index[:3]}, test_index: {test_index[:3]}\")\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    print(\"\\tX_train의 비율: %0.2f, X_test의 비율: %0.2f\" %(len(X_train)/len(X), len(X_test)/len(X)))\n",
    "    print(\"\\ttrain의 타겟 구성:\", Counter(y_train['target']))\n",
    "    print(\"\\ttest의 타겟 구성:\", Counter(y_test['target']))\n",
    "    print(\"\\ttrain의 그룹 구성:\", Counter(group.iloc[train_index]['group']))\n",
    "    print(\"\\ttest의 그룹 구성:\", Counter(group.iloc[test_index]['group']), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd6480-143c-4f13-9b24-44d3a683ede6",
   "metadata": {},
   "source": [
    "### **3-3. 교차 검증**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7aa989-df47-471f-99f7-50d73108d26b",
   "metadata": {},
   "source": [
    "#### 분할 샘플들로 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "693395d7-88ed-4b6c-aa21-aea2bb3fc6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time  test_score  train_score\n",
      "0  0.034606    0.001000    0.894737     0.955357\n",
      "1  0.005505    0.001000    0.947368     0.964286\n",
      "2  0.005000    0.001002    0.945946     0.955752\n",
      "3  0.004539    0.001018    1.000000     0.938053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = iris.drop('target', axis=1)\n",
    "y = iris['target']\n",
    "LOGREG = LogisticRegression(max_iter = 300, C = 0.1) # 학습 모델 정의\n",
    "SKF = StratifiedKFold(n_splits=4) # 데이터 분할 방법 정의\n",
    "result = cross_validate(LOGREG, X, y, cv = SKF, return_train_score=True) #교차 검증\n",
    "print(DataFrame(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6207aaf6-2b99-4e38-a5ff-a54bdaf3a90d",
   "metadata": {},
   "source": [
    "#### 파라미터 후보들로 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4e6d30d-1618-442d-9d50-edc04e39b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 교차 검증 점수: 0.97333\n",
      "최적의 매개변수: {'C': 1, 'solver': 'lbfgs'}\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
      "0       0.004003  7.077455e-04         0.001013    7.100861e-04     0.01   \n",
      "1       0.001250  4.323286e-04         0.000751    4.334305e-04     0.01   \n",
      "2       0.005782  8.424951e-04         0.000749    4.323620e-04     0.10   \n",
      "3       0.001517  4.837355e-04         0.000462    4.652702e-04     0.10   \n",
      "4       0.006763  5.498501e-04         0.001015    2.512150e-05     1.00   \n",
      "5       0.001000  5.591411e-07         0.001000    2.665601e-07     1.00   \n",
      "\n",
      "  param_solver                              params  split0_test_score  \\\n",
      "0        lbfgs      {'C': 0.01, 'solver': 'lbfgs'}           0.815789   \n",
      "1    liblinear  {'C': 0.01, 'solver': 'liblinear'}           0.684211   \n",
      "2        lbfgs       {'C': 0.1, 'solver': 'lbfgs'}           0.894737   \n",
      "3    liblinear   {'C': 0.1, 'solver': 'liblinear'}           0.815789   \n",
      "4        lbfgs         {'C': 1, 'solver': 'lbfgs'}           0.973684   \n",
      "5    liblinear     {'C': 1, 'solver': 'liblinear'}           1.000000   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
      "0           0.894737           0.783784           0.945946         0.860064   \n",
      "1           0.684211           0.648649           0.648649         0.666430   \n",
      "2           0.947368           0.945946           1.000000         0.947013   \n",
      "3           0.842105           0.837838           0.783784         0.819879   \n",
      "4           0.973684           0.945946           1.000000         0.973329   \n",
      "5           0.947368           0.864865           1.000000         0.953058   \n",
      "\n",
      "   std_test_score  rank_test_score  \n",
      "0        0.063947                4  \n",
      "1        0.017781                6  \n",
      "2        0.037221                3  \n",
      "3        0.023109                5  \n",
      "4        0.019114                1  \n",
      "5        0.055266                2  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "LOGREG = LogisticRegression(max_iter = 300) # 학습 모델 정의\n",
    "param_grid={'C':[0.01, 0.1, 1], 'solver':['lbfgs', 'liblinear']} #파라미터 후보 정의\n",
    "SKF = StratifiedKFold(n_splits=4) # 데이터 분할 방법 정의\n",
    "grid = GridSearchCV(LOGREG, param_grid, cv = SKF) #교차 검증\n",
    "grid.fit(X, y)\n",
    "print(\"최상의 교차 검증 점수: {:.5f}\".format(grid.best_score_))\n",
    "print(\"최적의 매개변수: {}\".format(grid.best_params_))\n",
    "print(DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40bd13-08d5-4089-9075-348f0fa8d3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e1bc260-83a0-4abe-bcbd-fecf65262fd1",
   "metadata": {},
   "source": [
    "#### 연습문제 #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b56262fb-a8e8-4667-9e52-fa839e2b4f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         job  marital  education default  balance housing loan  \\\n",
      "0   30  unemployed  married    primary      no     1787      no   no   \n",
      "1   33    services  married  secondary      no     4789     yes  yes   \n",
      "2   35  management   single   tertiary      no     1350     yes   no   \n",
      "\n",
      "    contact month   y  \n",
      "0  cellular   oct  no  \n",
      "1  cellular   may  no  \n",
      "2  cellular   apr  no  \n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "df = read_csv('https://raw.githubusercontent.com/algoboni/pythoncodebook1-1/main/practice1_bank.csv')\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68a28dbc-9912-422b-853b-9a1172295d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         job  marital  education default  balance housing loan  \\\n",
      "0   30  unemployed  married    primary      no     1787      no   no   \n",
      "1   33    services  married  secondary      no     4789     yes  yes   \n",
      "2   35  management   single   tertiary      no     1350     yes   no   \n",
      "\n",
      "    contact month   y  \n",
      "0  cellular   oct  no  \n",
      "1  cellular   may  no  \n",
      "2  cellular   apr  no  \n",
      "\n",
      "DICT 생성 확인\n",
      "['no' 'yes']\n",
      "[0, 1]\n",
      "{'no': 0, 'yes': 1}\n",
      "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
      "0   30    0        0          0        0     1787        0     0        0   \n",
      "1   33    1        0          1        0     4789        1     1        0   \n",
      "2   35    2        1          2        0     1350        1     0        0   \n",
      "\n",
      "   month  y  \n",
      "0      0  0  \n",
      "1      1  0  \n",
      "2      2  0  \n"
     ]
    }
   ],
   "source": [
    "# 범주형 변수들을 레이블 인코딩을 통해 전처리 한다.\n",
    "df2 = df.copy()\n",
    "for col in [i for i in df.columns if df2[i].dtypes==object]:\n",
    "    DICT = dict(zip(df2[col].unique(), range(df2[col].nunique())))\n",
    "    #DICT = dict(zip(df2[col].unique(), [i for i in range(df2[col].nunique())]))\n",
    "    df2[col] = df2[col].map(DICT)\n",
    "print(df.head(3))\n",
    "\n",
    "# 마지막 변수의 DICT 확인\n",
    "print(\"\\nDICT 생성 확인\")\n",
    "print(df[col].unique())\n",
    "print([i for i in range(df[col].nunique())])\n",
    "print(DICT)\n",
    "\n",
    "print(df2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27bddf4b-7a9a-437b-874b-46b02e2c48d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 교차 검증 점수: 0.88\n",
      "최적의 매개변수: {'max_depth': 7}\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.157216      0.022431         0.003956        0.000688   \n",
      "1       0.137484      0.001359         0.004351        0.001498   \n",
      "2       0.150318      0.004811         0.003681        0.001714   \n",
      "3       0.160886      0.001128         0.004721        0.000480   \n",
      "\n",
      "   param_max_depth            params  split0_test_score  split1_test_score  \\\n",
      "0                5  {'max_depth': 5}           0.885942           0.884615   \n",
      "1                6  {'max_depth': 6}           0.887268           0.883289   \n",
      "2                7  {'max_depth': 7}           0.885942           0.885942   \n",
      "3                8  {'max_depth': 8}           0.885942           0.883289   \n",
      "\n",
      "   split2_test_score  split3_test_score  split4_test_score  split5_test_score  \\\n",
      "0           0.881963           0.885790           0.883134           0.884462   \n",
      "1           0.881963           0.885790           0.883134           0.884462   \n",
      "2           0.883289           0.884462           0.885790           0.883134   \n",
      "3           0.881963           0.883134           0.885790           0.880478   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.884318        0.001406                2  \n",
      "1         0.884318        0.001775                2  \n",
      "2         0.884760        0.001208                1  \n",
      "3         0.883433        0.001952                4  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier() # 학습 모델 정의\n",
    "param_grid={'max_depth':[5, 6, 7, 8]} #파라미터 후보 정의\n",
    "SKF = StratifiedKFold(n_splits=6) # 데이터 분할 방법 정의\n",
    "grid = GridSearchCV(rf, param_grid, cv = SKF) #교차 검증\n",
    "\n",
    "X = df2.drop('y', axis=1)\n",
    "y = df2['y']\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"최상의 교차 검증 점수: {:.2f}\".format(grid.best_score_))\n",
    "print(\"최적의 매개변수: {}\".format(grid.best_params_))\n",
    "print(DataFrame(grid.cv_results_))\n",
    "# 매개변수들을 활용한 교차분석 결과, max_depth가 7일 때 가장 높은 성능을 보이는 것으로 확인하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d04d0-26d6-420e-bb63-8e37f7991fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5f66d-4967-4431-a726-719c8509c002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5089ad-cb00-455b-9a4f-97c24c85c3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e9f2b-5129-4c73-b5ca-21a6282a8bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c472f-4ae9-42f6-b779-3df0a9ffabc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1ba60-e1e1-4d41-8995-f071fa90dbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b06c5b-c686-4548-80dd-4dfb71ad90d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c547f-17d1-4636-8404-ccbb866bd6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4acb93-71dd-4f36-adbb-2608ae794153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f93e79-9cb3-4354-bf67-3f7d86b1e7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032c299-f08a-4af0-9b45-13cf4f37d38c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cf752-13d9-4052-9f00-d1f53c84a061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cebbbc-4aa6-4c6a-83a1-6eefd5e2c59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eeec47-05d6-434f-a487-d7e59c80679c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb34244-41a6-48fc-854f-e9a480441b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497f3a9-f967-421a-afcd-47385159bda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea252a-a296-47bf-b191-479d0b8064ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
